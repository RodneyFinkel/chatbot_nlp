{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma_me(sent):\n",
    "    sentence_tokens = nltk.word_tokenize(sent.lower())\n",
    "    pos_tags = nltk.pos_tag(sentence_tokens)\n",
    "\n",
    "    sentence_lemmas = []\n",
    "    for token, pos_tag in zip(sentence_tokens, pos_tags):\n",
    "        if pos_tag[1][0].lower() in ['n', 'v', 'a', 'r']:\n",
    "            lemma = lemmatizer.lemmatize(token, pos_tag[1][0].lower())\n",
    "            sentence_lemmas.append(lemma)\n",
    "    \n",
    "    return sentence_lemmas\n",
    "\n",
    "        \n",
    "x1 = lemma_me('the brown fox jumped over Neo and Nala')\n",
    "x2 = lemma_me('Vegetables are types of plants.')\n",
    "x3 = lemma_me('A vegetable is a kind of plant')\n",
    "x2_1 = lemma_me('A vegetable is a type of plant')\n",
    "print(x1, x2, x2_1, x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/rodneyfinkel/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rodneyfinkel/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rodneyfinkel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "text = 'Originally, vegetables were collected from the wild by hunter-gatherers. Vegetables are all plants. Vegetables can be eaten either raw or cooked.'\n",
    "question = 'What are vegetables?'\n",
    "\n",
    "def lemma_me(sent):\n",
    "    sentence_tokens = nltk.word_tokenize(sent.lower())\n",
    "    pos_tags = nltk.pos_tag(sentence_tokens)\n",
    "\n",
    "    sentence_lemmas = []\n",
    "    for token, pos_tag in zip(sentence_tokens, pos_tags):\n",
    "        if pos_tag[1][0].lower() in ['n', 'v', 'a', 'r']:\n",
    "            lemma = lemmatizer.lemmatize(token, pos_tag[1][0].lower())\n",
    "            sentence_lemmas.append(lemma)\n",
    "    \n",
    "    return sentence_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Originally, vegetables were collected from the wild by hunter-gatherers.',\n",
       " 'Vegetables are all plants.',\n",
       " 'Vegetables can be eaten either raw or cooked.',\n",
       " 'What are vegetables?']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_tokens = nltk.sent_tokenize(text)\n",
    "sentence_tokens.append(question)\n",
    "sentence_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27717414, 0.53114624, 0.        , 0.        , 0.53114624,\n",
       "        0.53114624, 0.        , 0.27717414],\n",
       "       [0.41988018, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.8046125 , 0.41988018],\n",
       "       [0.32713399, 0.        , 0.62688384, 0.62688384, 0.        ,\n",
       "        0.        , 0.        , 0.32713399],\n",
       "       [0.70710678, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.70710678]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tv = TfidfVectorizer(tokenizer=lemma_me)\n",
    "tf = tv.fit_transform(sentence_tokens)\n",
    "tf2 = tf.toarray()\n",
    "tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>be</th>\n",
       "      <th>collect</th>\n",
       "      <th>cook</th>\n",
       "      <th>eat</th>\n",
       "      <th>hunter-gatherer</th>\n",
       "      <th>originally</th>\n",
       "      <th>plant</th>\n",
       "      <th>vegetable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.277174</td>\n",
       "      <td>0.531146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.531146</td>\n",
       "      <td>0.531146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.419880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.804612</td>\n",
       "      <td>0.419880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.327134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.626884</td>\n",
       "      <td>0.626884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.327134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         be   collect      cook       eat  hunter-gatherer  originally  \\\n",
       "0  0.277174  0.531146  0.000000  0.000000         0.531146    0.531146   \n",
       "1  0.419880  0.000000  0.000000  0.000000         0.000000    0.000000   \n",
       "2  0.327134  0.000000  0.626884  0.626884         0.000000    0.000000   \n",
       "3  0.707107  0.000000  0.000000  0.000000         0.000000    0.000000   \n",
       "\n",
       "      plant  vegetable  \n",
       "0  0.000000   0.277174  \n",
       "1  0.804612   0.419880  \n",
       "2  0.000000   0.327134  \n",
       "3  0.000000   0.707107  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "df = pandas.DataFrame(tf2, columns=tv.get_feature_names())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39198343, 0.59380024, 0.46263733, 1.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise  import cosine_similarity\n",
    "values = cosine_similarity(tf[-1], tf)\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39198343, 0.46263733, 0.59380024, 1.        ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = values.argsort()[0][-2]\n",
    "\n",
    "values_flat = values.flatten()\n",
    "values_flat.sort()\n",
    "values_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.593800244493221"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff = values_flat[-2]\n",
    "coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vegetables are all plants.\n"
     ]
    }
   ],
   "source": [
    "if coeff > 0.3:\n",
    "    print(sentence_tokens[index])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
